{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tesorboard to images\n",
    "This function takes the directories for different experiments, and create images from the tensorboard files. The images are saved in the output directory given as an argument.\n",
    "\n",
    "Inputs:\n",
    "- `log_dirs`: List of directories containing the tensorboard files\n",
    "- `output_dir`: Directory where the images will be saved\n",
    "\n",
    "For more examples, check the example use case below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorboard_to_images(log_dirs, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Dictionary to hold aggregated data for each metric\n",
    "    aggregated_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    # Shortened names for legends\n",
    "    legend_names = {\n",
    "        'ForwardAndBackwardRaycastSoccerTwosRun': 'F&B Raycast',\n",
    "        'OnlyForwardRaycastSoccerTwosRun': 'Only F Raycast',\n",
    "        'SoundAndViewRotationSoccerTwosRun': 'Sound & View'\n",
    "    }\n",
    "\n",
    "    for log_dir in log_dirs:\n",
    "        method_name = legend_names.get(os.path.basename(log_dir), os.path.basename(log_dir))\n",
    "        for subdir, _, files in os.walk(log_dir):\n",
    "            for file in files:\n",
    "                if \"events.out.tfevents\" in file:\n",
    "                    event_file = os.path.join(subdir, file)\n",
    "                    ea = event_accumulator.EventAccumulator(event_file)\n",
    "                    ea.Reload()\n",
    "                    \n",
    "                    for tag in ea.Tags()['scalars']:\n",
    "                        events = ea.Scalars(tag)\n",
    "                        steps = [e.step for e in events]\n",
    "                        values = [e.value for e in events]\n",
    "                        \n",
    "                        # Append data to the corresponding metric (tag) and method\n",
    "                        aggregated_data[tag][method_name].append((steps, values))\n",
    "    \n",
    "    # Create a separate plot for each metric (tag)\n",
    "    for tag, methods in aggregated_data.items():\n",
    "        plt.figure(figsize=(12, 8))  # Set high resolution for the output image\n",
    "        \n",
    "        # Plot all methods for this metric\n",
    "        for method_name, data in methods.items():\n",
    "            # Aggregate steps and values for each method\n",
    "            all_steps = []\n",
    "            all_values = []\n",
    "            for steps, values in data:\n",
    "                all_steps.extend(steps)\n",
    "                all_values.extend(values)\n",
    "            \n",
    "            # Sort by steps and average values if needed\n",
    "            sorted_indices = np.argsort(all_steps)\n",
    "            sorted_steps = np.array(all_steps)[sorted_indices]\n",
    "            sorted_values = np.array(all_values)[sorted_indices]\n",
    "            \n",
    "            # Optionally average values for repeated steps\n",
    "            unique_steps, indices = np.unique(sorted_steps, return_inverse=True)\n",
    "            averaged_values = np.bincount(indices, weights=sorted_values) / np.bincount(indices)\n",
    "\n",
    "            # Plot the aggregated data\n",
    "            plt.plot(unique_steps, averaged_values, label=f\"{method_name}\")\n",
    "        \n",
    "        plt.xlabel('Steps')\n",
    "        plt.ylabel('Values')\n",
    "        plt.title(f'TensorBoard Scalars - {tag}')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save each plot to a separate file\n",
    "        output_image_name = f\"{tag.replace('/', '_')}.png\"\n",
    "        plt.savefig(os.path.join(output_dir, output_image_name), dpi=300)  # Save with high resolution\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "log_dirs = [\"ForwardAndBackwardRaycastSoccerTwosRun\", \"OnlyForwardRaycastSoccerTwosRun\", \"SoundAndViewRotationSoccerTwosRun\"]\n",
    "output_dir = \"results\"\n",
    "tensorboard_to_images(log_dirs, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
